---
title: 机器学习
date: 2018-8-27 20:09:04
tags: [机器学习]

---

### 机器学习的算法分类
一般来说 可以分为两大类
- 监督学习 （预测）（监督学习可以分为三类）  
   - 分类 K-近邻算法，贝叶斯分类，决策树与随机森林，逻辑回归，神经网络
   - 回归 线性回归、 岭回归
   - 标注 隐马尔科夫模型
   ```
    分类：训练目标值是离散型   类似将一个文章进行分类，这个文章是 科技的还是体育的 这是个
         离散的值
    回归：训练目标值是连续的    类似 预测股票的涨跌  预测某个人对某件物品的偏好值，对某个电影的偏好值
   ```
- 非监督学习
   - 聚类  K-means
```
一般来说 监督学习给出的训练集有 ： 特征值+目标值  （有标准答案来训练）
类似线性回归，决策树之类 都是通过 特征值+目标值 训练出来的
非监督学习给出的训练集只有：特征值 （无标准答案）
```
## K-近邻算法(kNN，k-Nearest Neighbor)
定义：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)
的样本中的大多数属于某一个类别，则该样本也属于这个类别。

## 朴素贝叶斯
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304084752.png)

在预测文档的类别这类题目中
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304095656.png)
在训练集中 我们通过 TF-IDF 将重要的词统计出
后面我们进行特征工程的处理
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304095405.png)  
科技类别中 影院在100个词中出现过8次 所以概率为 8/100   科技这类文章在所有的90篇文章中出现了30篇 所以概率为 30/90  
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304100004.png)
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304100331.png)
纠正后如下
m为训练文档中统计出的特征词个数 我们特征词有  影院，支付宝，云计算，商场  为4  而不是3 
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304100754.png)
因为概率不一样
一测温  
``` 
模型：算法+数据
模型的评估：判定效果如何
```
## 线性回归
```
通过大量样本的试验学习到线性函数，然后根据新的样本外的特征预测结果
```
多元线性回归分析：如果自变量多于1个，那么就要求一个多元函数去拟合空间中的点。

![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223174318.png)
  
  
 
 ## 协同过滤
 
 协同过滤算法主要用于推荐系统，推荐系统是信息过载所采用的措施，面对海量的数据信息，从中快速推荐出符合用户特点的物品。一些人的“选择恐惧症”、没有明确需求的人。
 - To C （对用户而言）解决如何从大量信息中找到自己感兴趣的信息。
 - To B （对企业而言）解决如何让自己生产的信息脱颖而出
 
 
### 推荐数据的准备
如果需要推荐一个物品 那么物品应该要有这三个属性
```
 用户ID、物品ID、偏好值
```
偏好值：就是用户对物品的喜爱程度，推荐系统所做的事就是根据这些数据为用户推荐他还没有见过
的物品，并且猜测这个物品用户喜欢的概率比较大

用户ID和物品ID一般通过系统的业务数据库就可以获得，
偏好值的采集一般会有很多办法，比如评分、投票、转发、保存书签、页面停留时间等等，
然后系统根据用户的这些行为流水，采取减噪、归一化、加权等方法综合给出偏好值。
一般不同的业务系统给出偏好值的计算方法不一样。

![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223182654.png)

- 皮尔逊相关系数 是什么
数学含义： 两个序列协方差与两者方差乘积的值
皮尔逊相关系数是两个序列 一起增大或一起减小的可能性
假设A 和 B 两个人  都对 abcded 这几个商品感兴趣
A 对 a打分5分  B 对 a打分4.5 
A 对 b打分4.7分  B 对 a打分4.9

大量数据 可以判定 A 和 B  的为正相关，趋近于1
- 皮尔逊相关系数 
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223234943.png)

- 欧几里得距离
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223234828.png)
 
### 协同过滤 UserCF
User CF （Collaborative Filter） 基于用户的CF  
假设商品a  有和你相似度量最接近的5个人买
用户 A对它 a打分4 分   用户A 和你的 相似度是0.8
用户 B对它 a打分4.5 分   用户B 和你的 相似度是0.7
用户 C对它 a打分5 分   用户C 和你的 相似度是0.75

那么会用 (4*0.8+4.5*0.7+5*0.75)/ 平均值  这种方式对

![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190224010321.png)
### 协同过滤 itemCF
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190224010611.png)

### ALS 算法（Alternative Least Squares）
spark mllib 里面 没有对 UserCF 和  ItemCF 进行实现
只对 ALS 算法进行了实现 ALS 是对 UserCF 和 ItemCF 的一些综合实现
我们把打分理解成相似度，那么
**“打分矩阵A(m*n)”**   就可以由
**“用户喜好特征矩阵U(m*k)”**  和
**“产品特征矩阵V(n*k)”**    的乘积 来近似了
。这种方法被称为概率矩阵分解算法(probabilistic matrix factorization，PMF)
。ALS算法是PMF在数值计算方面的应用。

