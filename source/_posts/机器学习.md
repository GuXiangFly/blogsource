---
ODS、DWD、DWSODS、DWD、DWStitle: 机器学习
date: 2018-8-27 20:09:04
tags: [机器学习]

---

### 机器学习的算法分类
一般来说 可以分为两大类
- 监督学习 （预测）（监督学习可以分为三类）  
   - 分类 K-近邻算法，贝叶斯分类，决策树与随机森林，逻辑回归，神经网络
   - 回归 线性回归、 岭回归
   - 标注 隐马尔科夫模型
   ```
    分类：训练目标值是离散型   类似将一个文章进行分类，这个文章是 科技的还是体育的 这是个
         离散的值
    回归：训练目标值是连续的    类似 预测股票的涨跌  预测某个人对某件物品的偏好值，对某个电影的偏好值
   ```
- 非监督学习
  
   - 聚类  K-means
```
一般来说 监督学习给出的训练集有 ： 特征值+目标值  （有标准答案来训练）
类似线性回归，决策树之类 都是通过 特征值+目标值 训练出来的
非监督学习给出的训练集只有：特征值 （无标准答案）
```
## K-近邻算法(kNN，k-Nearest Neighbor)
定义：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)
的样本中的大多数属于某一个类别，则该样本也属于这个类别。

## 朴素贝叶斯
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304084752.png)

在预测文档的类别这类题目中
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304095656.png)
在训练集中 我们通过 TF-IDF 将重要的词统计出
后面我们进行特征工程的处理
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304095405.png)  
科技类别中 影院在100个词中出现过8次 所以概率为 8/100   科技这类文章在所有的90篇文章中出现了30篇 所以概率为 30/90  
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304100004.png)
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304100331.png)
纠正后如下
m为训练文档中统计出的特征词个数 我们特征词有  影院，支付宝，云计算，商场  为4  而不是3 
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190304100754.png)
因为概率不一样
一测温  
``` 
模型：算法+数据
模型的评估：判定效果如何
```
## 线性回归
```
通过大量样本的试验学习到线性函数，然后根据新的样本外的特征预测结果
```
多元线性回归分析：如果自变量多于1个，那么就要求一个多元函数去拟合空间中的点。

![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223174318.png)

  

 ## 协同过滤

 协同过滤算法主要用于推荐系统，推荐系统是信息过载所采用的措施，面对海量的数据信息，从中快速推荐出符合用户特点的物品。一些人的“选择恐惧症”、没有明确需求的人。
 - To C （对用户而言）解决如何从大量信息中找到自己感兴趣的信息。
 - To B （对企业而言）解决如何让自己生产的信息脱颖而出


### 推荐数据的准备
如果需要推荐一个物品 那么物品应该要有这三个属性
```
 用户ID、物品ID、偏好值
```
偏好值：就是用户对物品的喜爱程度，推荐系统所做的事就是根据这些数据为用户推荐他还没有见过
的物品，并且猜测这个物品用户喜欢的概率比较大

用户ID和物品ID一般通过系统的业务数据库就可以获得，
偏好值的采集一般会有很多办法，比如评分、投票、转发、保存书签、页面停留时间等等，
然后系统根据用户的这些行为流水，采取减噪、归一化、加权等方法综合给出偏好值。
一般不同的业务系统给出偏好值的计算方法不一样。

![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223182654.png)

- 皮尔逊相关系数 是什么
数学含义： 两个序列协方差与两者方差乘积的值
皮尔逊相关系数是两个序列 一起增大或一起减小的可能性
假设A 和 B 两个人  都对 abcded 这几个商品感兴趣
A 对 a打分5分  B 对 a打分4.5 
A 对 b打分4.7分  B 对 a打分4.9

大量数据 可以判定 A 和 B  的为正相关，趋近于1
- 皮尔逊相关系数 
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223234943.png)

- 欧几里得距离
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190223234828.png)

### 协同过滤 UserCF
User CF （Collaborative Filter） 基于用户的CF  
假设商品a  有和你相似度量最接近的5个人买
用户 A对它 a打分4 分   用户A 和你的 相似度是0.8
用户 B对它 a打分4.5 分   用户B 和你的 相似度是0.7
用户 C对它 a打分5 分   用户C 和你的 相似度是0.75

那么会用 (4*0.8+4.5*0.7+5*0.75)/ 平均值  这种方式对

![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190224010321.png)
### 协同过滤 itemCF
![](https://raw.githubusercontent.com/GuXiangFly/imagerepo/master/20190224010611.png)

### ALS 算法（Alternative Least Squares）
spark mllib 里面 没有对 UserCF 和  ItemCF 进行实现
只对 ALS 算法进行了实现 ALS 是对 UserCF 和 ItemCF 的一些综合实现
我们把打分理解成相似度，那么
**“打分矩阵A(m*n)”**   就可以由
**“用户喜好特征矩阵U(m*k)”**  和
**“产品特征矩阵V(n*k)”**    的乘积 来近似了
。这种方法被称为概率矩阵分解算法(probabilistic matrix factorization，PMF)
。ALS算法是PMF在数值计算方面的应用。





## TensorFlow 基础学习

- 创建一张图包含了一组op和tensor

  - op： 只要使用TensorFlow的API定义的函数都是op

    - 下面的程序中 `tf.constant ` ,`tf.add` ,`tf.Variable` ，`tf.get_default_graph`这些都是op

    ```python
    import tensorflow as tf
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    
    a = tf.constant(5.0)
    b = tf.constant(6.0)
    data2 = tf.Variable(10, name='var')
    sum1 = tf.add(a, b)
    
    # 定义一张图，相当于给程序分配一段内存
    graph = tf.get_default_graph()
    with tf.Session(graph=graph) as sess:
        print(sess.run(sum1))
    ```

    

  - 张量Tensor

    - 5.0 ，6.0  这些常量是张量

  - 变量

    - `10, name='var'` 这个就是变量

- graph 

  -  定义一张图，相当于给程序**分配一段内存**

- Session （会话）

  - tf.Session()
    运行TensorFlow操作图的类，使用默认注册的图（可以指定运行图）

  - 会话资源

    - 会话可能拥有很多资源，如 tf.Variable，tf.QueueBase和tf.ReaderBase，会话结束后需要进行资源释放

  - sess = tf.Session()    

    -  sess.run(...)      run是启动这个图，可以run多次

    - sess.close() 

      - 使用上下文管理器  运行完代码块后，会自己调用sess.close() 
        with tf.Session() as sess: 
        	sess.run(...)

    - 使用config=tf.ConfigProto(log_device_placement=True) 可以打印出在哪个CPU运行的
      ```python
      graph = tf.get_default_graph()
      with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:
          #print(sess.run(sum1))
          print（sum1.eval()）
      ```
      
    - 交互式：tf.InteractiveSession()



##### 重载运算符运行

- `sum2 = a + c ` 由于a 是张量， 执行程序的时候  c也会转为张量， +操作会转为tf.add(....)

```python
a = tf.constant(5.0)
b = tf.constant(6.0)
sum1 = tf.add(a, b)
c = 10.0

sum2 = a + c

# 定义一张图，相当于给程序分配一段内存
graph = tf.get_default_graph()
with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:
    print(sess.run(sum1))
    print(sess.run(sum2))
    print(sess.run([a, b, sum1, sum2]))
```



##### placeholder 占位符

- 意义：在程序执行的时候,不确定输入的是什么，提前“占个坑”
- 语法：placeholder提供占位符，run时候通过feed_dict指定参数

```python
import tensorflow as tf
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
# 这个代表给的数据必须是两行三列的
tf.placeholder(tf.float32, [2, 3])
# 这个代表给的数据可以是不固定行数，三列的
plt = tf.placeholder(tf.float32, [None, 3])
# 定义一张图，相当于给程序分配一段内存
graph = tf.get_default_graph()
with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:
    print(sess.run(plt, feed_dict={plt: [
        [1, 2, 3],
        [2, 66, 3],
        [3, 4, 3],
        [1, 78, 3],
    ]}))
```



##### 张量

- 1、张量的阶和数据类型
  - tensor 是对 numpy的 ndarray 进行了封装
-  2、张量操作





```python

# tensorflow:打印出来的形状表示
# 0维：()   1维:(5)  2维：(5,6)   3维：(2,3,4)

# 形状的概念
# 静态形状和动态性状
# 对于静态形状来说，一旦张量形状固定了，不能再次设置静态形状, 不能夸维度修改 1D->1D 2D->2D
# 动态形状可以去创建一个新的张量,改变时候一定要注意元素数量要匹配  1D->2D  1->3D
#
 plt = tf.placeholder(tf.float32, [None, 2])
 print(plt)
 plt.set_shape([3, 2, 1])
 print(plt)
 # plt.set_shape([2, 3]) # 不能再次修改
 plt_reshape = tf.reshape(plt, [3, 3])
 print(plt_reshape)
 with tf.Session() as sess:
```



##### 变量

-  变量op

  - 1、变量op能够持久化保存，普通张量op是不行的

  - 2、当定义一个变量op的时候，一定要在会话当中去运行初始化

    - ```python
      init_op = tf.global_variables_initializer()
      
      with tf.Session() as sess:
        sess.run(init_op)
      ```

  - 3、name参数：在tensorboard使用的时候显示名字，可以让相同op名字的进行区分





#### TensorBoard

- **显示TensorBoard**

  数据序列化-events文件

  TensorBoard 通过读取 TensorFlow 的事件文件来运行。TensorFlow 的事件文件包括了你会在 TensorFlow 运行中涉及到的主要数据。事件文件的生成通过在程序中指定tf.summary.FileWriter存储的目录,以及要运行的图

  ```python
  tf.summary.FileWriter('/tmp/summary/test/', graph=default_graph)
  ```

- **启动TensorBoard**

  要运行TensorBoard，请使用以下命令

  ```
  tensorboard --logdir="path/to/log-directory"
  ```




##### TensorBoard 基础查看

![](https://i.loli.net/2020/04/17/FoSBqOTA4E9tgf7.png)





variable通过 random_normal 进行初始化，并且生成的是2x3的矩阵

![](https://i.loli.net/2020/04/17/CbOM1IxWHJLFUyG.png)



## 神经网络

神经网络 用于模拟这个过程：

1. 人接触到水杯，收集到温度  （轴突末梢）
2. 温度在神经元中传递 （轴突）
3. 心中有个默认的感觉，高于哪个温度就放下，低于哪个温度就可以喝

<img src="https://gitee.com/guxiangfly/blogimage/raw/master/img/image-20200528205902569.png" alt="image-20200528205902569" style="zoom:50%;" />

#### 感知机

感知机用于解决分类问题。

有n个输入的数据，通过权重与各数据之间的计算和， 比较激活函数的输出结果，得出结论。

<img src="https://gitee.com/guxiangfly/blogimage/raw/master/img/image-20200528211015273.png" alt="image-20200528211015273" style="zoom:50%;" />



#### 神经网络的特点

输入向量的维度和输入神经元的个数相同
每个连接都有个权值
同一层神经元之间没有连接
由输入层，隐层，输出层组成
第N层与第N-1层的所有神经元连接，也叫全连接（隐层中的最后一层和输出层的连接叫做全连接层，隐层中的最后一层的神经元个数和输出层的结果个数一致）

<img src="https://gitee.com/guxiangfly/blogimage/raw/master/img/image-20200529093531413.png" alt="image-20200529093531413" style="zoom:50%;" />



- 正向传播：输入经过一层一层计算得出输出。

- 反向传播：从损失计算开始，梯度下降更新权重。

假设有个图片是 28x28的图片，内容是数字1，我们想识别数字。

那么就是 28x28=784个元素输入进入 每个神经元，由于这个模型只有一层，又由于输出层类别有0~9 这么10种，所以全连接层就是10个神经元。

 

784对10个神经元每个神经元都进行计算，就得出了10个结果，对十个结果都进行softmax，得到概率值。 得到概率值后进行 交叉熵损失计算。  交叉熵损失计算公式如图，


$$
softmax(*x*)*i*=∑*j*exp(*x**j*)exp(*x**i*) 
$$
*H**y*′(*y*)=−∑*i**y**i*′*l**o**g*(*y**i*)

<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>H</mi><mrow><msup><mi>y</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></msub><mo>(</mo><mi>y</mi><mo>)</mo><mrow><mo>=</mo></mrow><mo>−</mo><msub><mo>∑</mo><mi>i</mi></msub><msubsup><mi>y</mi><mi>i</mi><mrow><mi mathvariant="normal">′</mi></mrow></msubsup><mi>l</mi><mi>o</mi><mi>g</mi><mrow><mo fence="true">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">H_{y'}(y){=}-\sum_iy'_ilog\left(y_i\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.0519020000000001em;vertical-align:-0.30001em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.08125em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"><span class="mord mathrm mtight">′</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span></span></span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord textstyle uncramped"><span class="mrel">=</span></span><span class="mbin">−</span><span class="mop"><span class="mop op-symbol small-op" style="top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist"><span style="top:0.30001em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span></span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:0.258664em;margin-left:-0.03588em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">′</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span></span></span></span></span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="minner textstyle uncramped"><span class="mopen style-wrap reset-textstyle textstyle uncramped" style="top:0em;">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;"></span></span></span></span></span></span><span class="mclose style-wrap reset-textstyle textstyle uncramped" style="top:0em;">)</span></span></span></span></span></p>

![image-20200602094743991](https://gitee.com/guxiangfly/blogimage/raw/master/img/image-20200602094743991.png)

假设我们是1，